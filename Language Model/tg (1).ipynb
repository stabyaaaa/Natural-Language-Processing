{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX3JmfMiAaTH"
      },
      "source": [
        "# LSTM Language Models\n",
        "\n",
        "You guys probably very excited about ChatGPT.  In today class, we will be implementing a very simple language model, which is basically what ChatGPT is, but with a simple LSTM.  You will be surprised that it is not so difficult at all.\n",
        "\n",
        "Paper that we base on is *Regularizing and Optimizing LSTM Language Models*, https://arxiv.org/abs/1708.02182"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om-OYP9aCdDY",
        "outputId": "19f4b2cd-11b9-412d-91f7-33e6de49907d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s8AnZMLuAaTJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext, datasets, math\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENQXNl_6AaTK",
        "outputId": "a88133b9-4c62-4593-fd99-1dee2067bfb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hyzJZQ-zAaTL"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDemYujEAaTL"
      },
      "source": [
        "## 1. Load data - Wiki Text\n",
        "\n",
        "We will be using wikitext which contains a large corpus of text, perfect for language modeling task.  This time, we will use the `datasets` library from HuggingFace to load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Rh7nkqJBAaTL"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('imdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mmy1UvCAaTL",
        "outputId": "4eda648d-12da-4951-b79e-c2d62e7cdaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 25000\n",
            "    })\n",
            "    unsupervised: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_1z3uNDAaTL",
        "outputId": "2b5d698c-1a36-4a5d-a5ba-aa428c718bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(dataset['train'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlcwPQqmAaTM"
      },
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlydBJMrAaTM"
      },
      "source": [
        "### Tokenizing\n",
        "\n",
        "Simply tokenize the given text to tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kP1OxKbzAaTM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "a9b83ea421064bc694c72d3313afcc7e",
            "e4b46668887d4a41bbd091536dd1c458",
            "c40e3009eddd46a7a0cf3d875843f979",
            "cd1db1de2f764317be63eaa62342d3ec",
            "8ef21616aee947c9899a2e5e16f36c89",
            "8ada2fe3a239454687876f99a6d26e8e",
            "af3a031889694fc7a8aa18473453a771",
            "594871d79ce94743bbc47dd402a9257b",
            "b721e3d72913466c8c05e4b4813875b3",
            "64e92b3b1e5d4e9082928e25453f86c7",
            "64f7e2a926a94d6390f7d793a338e26b",
            "e3299572c8ed4f6e9fab21828ed7e66a",
            "dea9b9245f374ff28e0b68ad6b297827",
            "5e4f98ea859c4ed9bd8dc5824406d5ea",
            "a672667720f643a39a1ed0027f16d7b1",
            "0a4a1b4ad11949ba99516394997ecedb",
            "af05515866de4362864128815f9711a9",
            "e17a9d9f2b9d4ea5b06de66d83d89908",
            "b8252c272a494dffa3373534ac79fad2",
            "e0e1b80ba96946ba8ff81ea8e248451e",
            "a59f6ca892b84f0c967aeac3934090e6",
            "2e60932808c74a1283146f5258a190eb",
            "61d1aafcdd84400682678f5f363a9abf",
            "25749ec8120e454dbd48a6311dae17ec",
            "4623a2ad99b94457b84c01bb2dbe9dfe",
            "bfd32cfabf3140ec9fe0f5586cdbe322",
            "a198e66eae244356b6e3e0a879a77b59",
            "d5463205ff5e4a33b5d61167c23a40e9",
            "3ee5d49aa9d34bd497a75773979e36fa",
            "322880b88e304e869c624eb100c1a7e4",
            "c55e553f6e704797bc7121b5d0892c8b",
            "0a07c4425c1a4454b30bf8090600b313",
            "e07801ab067e4f64a02b8571ffcbd5dd"
          ]
        },
        "outputId": "be3bc110-5b3a-4471-d979-ef0858c692f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9b83ea421064bc694c72d3313afcc7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3299572c8ed4f6e9fab21828ed7e66a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d1aafcdd84400682678f5f363a9abf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "\n",
        "tokenize_data = lambda example, tokenizer: {'tokens': tokenizer(example['text'])}\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_data, remove_columns=['text'], fn_kwargs={'tokenizer': tokenizer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4LmH8mxAaTM",
        "outputId": "6b0da094-8b3c-4254-ccf3-4d0b6bc595a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['if', 'the', 'term', 'itself', 'were', 'not', 'geographically', 'and', 'semantically', 'meaningless', ',', 'one', 'might', 'well', 'refer', 'to', 'ned', 'kelly', 'as', 'an', 'australian', 'western', '.', 'for', 'the', 'people', 'down', 'under', ',', 'ned', 'kelly', 'was', ',', 'apparently', ',', 'a', 'folk', 'hero', 'bandit', 'akin', 'to', 'robin', 'hood', ',', 'jesse', 'james', ',', 'bonnie', 'and', 'clyde', ',', 'and', 'butch', 'cassidy', 'and', 'the', 'sundance', 'kid', '.', 'the', 'descendant', 'of', 'irish', 'immigrants', ',', 'kelly', 'became', 'a', 'fugitive', 'and', 'an', 'outlaw', 'after', 'he', 'was', 'falsely', 'accused', 'of', 'shooting', 'an', 'australian', 'law', 'officer', ',', 'a', 'crime', 'for', 'which', 'his', 'equally', 'innocent', 'mother', 'was', 'put', 'into', 'prison', '.', 'to', 'get', 'back', 'at', 'the', 'government', 'for', 'this', 'mistreatment', ',', 'kelly', ',', 'his', 'brother', 'dan', ',', 'and', 'two', 'other', 'companions', ',', 'became', 'notorious', 'bank', 'robbers', ',', 'winning', 'over', 'the', 'hearts', 'of', 'many', 'people', 'in', 'the', 'countryside', 'while', 'striking', 'a', 'blow', 'for', 'justice', 'in', 'a', 'land', 'where', 'irish', 'immigrants', 'were', 'often', 'treated', 'with', 'disrespect', 'and', 'disdain', 'by', 'those', 'who', 'ran', 'the', 'country', '.', 'perhaps', 'because', 'we', \"'\", 've', 'encountered', 'this', 'gentleman', 'bandit', 'scenario', 'so', 'many', 'times', 'in', 'the', 'past', ',', 'ned', 'kelly', 'feels', 'awfully', 'familiar', 'and', 'unoriginal', 'as', 'it', 'pays', 'homage', 'to', 'any', 'number', 'of', 'the', 'genre', \"'\", 's', 'stereotypes', 'and', 'clichés', 'on', 'its', 'way', 'to', 'the', 'inevitable', 'showdown', '.', 'ned', 'is', 'the', 'typical', 'heart-of-gold', 'lawbreaker', 'who', 'kills', 'only', 'when', 'he', 'is', 'forced', 'to', 'and', ',', 'even', 'then', ',', 'only', 'with', 'the', 'deepest', 'regret', '.', 'he', 'also', 'has', 'the', 'pulse', 'of', 'the', 'common', 'folk', ',', 'as', 'when', ',', 'in', 'the', 'middle', 'of', 'a', 'bank', 'robbery', ',', 'he', 'returns', 'a', 'valuable', 'watch', 'to', 'one', 'of', 'the', 'customers', ',', 'after', 'one', 'of', 'his', 'gang', 'has', 'so', 'inconsiderately', 'pilfered', 'it', '.', 'what', 'movie', 'on', 'this', 'particular', 'subject', 'hasn', \"'\", 't', 'featured', 'a', 'scene', 'like', 'that', '?', 'it', \"'\", 's', 'acts', 'of', 'selective', 'generosity', 'like', 'this', ',', 'of', 'course', ',', 'that', 'earn', 'him', 'the', 'love', 'and', 'respect', 'of', 'all', 'the', 'little', 'people', 'who', 'come', 'to', 'secretly', 'admire', 'anyone', 'who', 'can', 'get', 'away', 'with', 'sticking', 'it', 'to', 'the', 'powers-that-be', 'and', 'the', 'status', 'quo', '.', 'geoffrey', 'rush', 'plays', 'the', 'typical', 'bedeviled', 'law', 'enforcer', 'who', 'feels', 'a', 'personal', 'stake', 'in', 'bringing', 'down', 'this', 'upstart', 'troublemaker', 'who', 'keeps', 'getting', 'away', 'with', 'tweaking', 'the', 'establishment', '.', 'there', \"'\", 's', 'even', 'the', 'inevitable', 'episode', 'in', 'which', 'one', 'of', 'the', 'ladies', 'being', 'held', 'up', 'goes', 'into', 'the', 'next', 'room', 'and', 'has', 'sex', 'with', 'one', 'of', 'the', 'robbers', ',', 'so', 'turned', 'on', 'is', 'she', 'by', 'the', 'romantic', 'derring-do', 'of', 'the', 'criminal', 'lifestyle', '.', 'and', 'the', 'film', 'is', 'riddled', 'with', 'one', 'hackneyed', 'scene', 'like', 'this', 'after', 'another', '.', 'heath', 'ledger', 'fails', 'to', 'distinguish', 'himself', 'in', 'the', 'title', 'role', ',', 'providing', 'little', 'in', 'the', 'way', 'of', 'substance', 'to', 'make', 'his', 'character', 'either', 'interesting', 'or', 'engaging', '.', 'it', 'doesn', \"'\", 't', 'help', 'that', 'he', 'has', 'been', 'forced', 'to', 'provide', 'a', 'droning', 'voice-over', 'narration', 'that', 'underlines', 'the', 'sanctimoniousness', 'and', 'pretentiousness', 'of', 'both', 'the', 'character', 'and', 'the', 'film', '.', 'ned', 'kelly', 'might', 'serve', 'a', 'function', 'of', 'sorts', 'as', 'a', 'lesson', 'in', 'australian', 'history', ',', 'but', 'as', 'an', 'entertainment', ',', 'it', \"'\", 's', 'just', 'the', 'same', 'old', 'story', 'told', 'with', 'different', 'accents', '.']\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_dataset['train'][55]['tokens'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KOFCCFbAaTM"
      },
      "source": [
        "### Numericalizing\n",
        "\n",
        "We will tell torchtext to add any word that has occurred at least three times in the dataset to the vocabulary because otherwise it would be too big.  Also we shall make sure to add `unk` and `eos`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-3wxBroDAaTM"
      },
      "outputs": [],
      "source": [
        "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_dataset['train']['tokens'], min_freq=3)\n",
        "vocab.insert_token('<unk>', 0)\n",
        "vocab.insert_token('<eos>', 1)\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pImh3R5sAaTM",
        "outputId": "f48a77ad-4bc3-4cd1-8331-e380ecaf3c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40252\n"
          ]
        }
      ],
      "source": [
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mx5clxGAaTM",
        "outputId": "6992441d-6254-467d-ae13-1f54a2433a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<eos>', 'the', '.', ',', 'and', 'a', 'of', 'to', \"'\"]\n"
          ]
        }
      ],
      "source": [
        "print(vocab.get_itos()[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKidTqL0AaTM"
      },
      "source": [
        "## 3. Prepare the batch loader\n",
        "\n",
        "### Prepare data\n",
        "\n",
        "Given \"Chaky loves eating at AIT\", and \"I really love deep learning\", and given batch size = 3, we will get three batches of data \"Chaky loves eating at\", \"AIT `<eos>` I really\", \"love deep learning `<eos>`\".  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZsK7dxakAaTN"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset, vocab, batch_size):\n",
        "    data = []\n",
        "    for example in dataset:\n",
        "        if example['tokens']:\n",
        "            tokens = example['tokens'].append('<eos>')\n",
        "            tokens = [vocab[token] for token in example['tokens']]\n",
        "            data.extend(tokens)\n",
        "    data = torch.LongTensor(data)\n",
        "    num_batches = data.shape[0] // batch_size\n",
        "    data = data[:num_batches * batch_size]\n",
        "    data = data.view(batch_size, num_batches) #view vs. reshape (whether data is contiguous)\n",
        "    return data #[batch size, seq len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p61yhDnJAaTN"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_data = get_data(tokenized_dataset['train'], vocab, batch_size)\n",
        "valid_data = get_data(tokenized_dataset['unsupervised'], vocab, batch_size)\n",
        "test_data  = get_data(tokenized_dataset['test'],  vocab, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDT6WXGTAaTN",
        "outputId": "d4a6f437-b666-427c-8622-db5af75e6189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 53063])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikAjPIT7AaTN"
      },
      "source": [
        "## 4. Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yrwRFbXAaTN"
      },
      "source": [
        "<img src=\"figures/LM.png\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "l_qfRLBQAaTN"
      },
      "outputs": [],
      "source": [
        "class LSTMLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, num_layers, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hid_dim    = hid_dim\n",
        "        self.emb_dim    = emb_dim\n",
        "\n",
        "        self.embedding  = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm       = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers, dropout=dropout_rate, batch_first=True)\n",
        "        self.dropout    = nn.Dropout(dropout_rate)\n",
        "        self.fc         = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        init_range_emb = 0.1\n",
        "        init_range_other = 1/math.sqrt(self.hid_dim)\n",
        "        self.embedding.weight.data.uniform_(-init_range_emb, init_range_other)\n",
        "        self.fc.weight.data.uniform_(-init_range_other, init_range_other)\n",
        "        self.fc.bias.data.zero_()\n",
        "        for i in range(self.num_layers):\n",
        "            self.lstm.all_weights[i][0] = torch.FloatTensor(self.emb_dim,\n",
        "                self.hid_dim).uniform_(-init_range_other, init_range_other) #We\n",
        "            self.lstm.all_weights[i][1] = torch.FloatTensor(self.hid_dim,\n",
        "                self.hid_dim).uniform_(-init_range_other, init_range_other) #Wh\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hid_dim).to(device)\n",
        "        cell   = torch.zeros(self.num_layers, batch_size, self.hid_dim).to(device)\n",
        "        return hidden, cell\n",
        "\n",
        "    def detach_hidden(self, hidden):\n",
        "        hidden, cell = hidden\n",
        "        hidden = hidden.detach() #not to be used for gradient computation\n",
        "        cell   = cell.detach()\n",
        "        return hidden, cell\n",
        "\n",
        "    def forward(self, src, hidden):\n",
        "        #src: [batch_size, seq len]\n",
        "        embedding = self.dropout(self.embedding(src)) #harry potter is\n",
        "        #embedding: [batch-size, seq len, emb dim]\n",
        "        output, hidden = self.lstm(embedding, hidden)\n",
        "        #ouput: [batch size, seq len, hid dim]\n",
        "        #hidden: [num_layers * direction, seq len, hid_dim]\n",
        "        output = self.dropout(output)\n",
        "        prediction =self.fc(output)\n",
        "        #prediction: [batch_size, seq_len, vocab_size]\n",
        "        return prediction, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0HM0nfWAaTN"
      },
      "source": [
        "## 5. Training\n",
        "\n",
        "Follows very basic procedure.  One note is that some of the sequences that will be fed to the model may involve parts from different sequences in the original dataset or be a subset of one (depending on the decoding length). For this reason we will reset the hidden state every epoch, this is like assuming that the next batch of sequences is probably always a follow up on the previous in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "36ynSWGoAaTN"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "emb_dim = 1024                # 400 in the paper\n",
        "hid_dim = 1024                # 1150 in the paper\n",
        "num_layers = 2                # 3 in the paper\n",
        "dropout_rate = 0.65\n",
        "lr = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkGOHf4DAaTN",
        "outputId": "3afeabbd-e61f-4a33-b957-5f93f6cdb3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 99,269,948 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "model      = LSTMLanguageModel(vocab_size, emb_dim, hid_dim, num_layers, dropout_rate).to(device)\n",
        "optimizer  = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'The model has {num_params:,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Q1GDSzxfAaTN"
      },
      "outputs": [],
      "source": [
        "def get_batch(data, seq_len, idx):\n",
        "    #data #[batch size, bunch of tokens]\n",
        "    src    = data[:, idx:idx+seq_len]\n",
        "    target = data[:, idx+1:idx+seq_len+1]  #target simply is ahead of src by 1\n",
        "    return src, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yoEeYUQdAaTN"
      },
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    # drop all batches that are not a multiple of seq_len\n",
        "    # data #[batch size, seq len]\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]  #we need to -1 because we start at 0\n",
        "    num_batches = data.shape[-1]\n",
        "\n",
        "    #reset the hidden every epoch\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "\n",
        "    for idx in tqdm(range(0, num_batches - 1, seq_len), desc='Training: ',leave=False):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #hidden does not need to be in the computational graph for efficiency\n",
        "        hidden = model.detach_hidden(hidden)\n",
        "\n",
        "        src, target = get_batch(data, seq_len, idx) #src, target: [batch size, seq len]\n",
        "        src, target = src.to(device), target.to(device)\n",
        "        batch_size = src.shape[0]\n",
        "        prediction, hidden = model(src, hidden)\n",
        "\n",
        "        #need to reshape because criterion expects pred to be 2d and target to be 1d\n",
        "        prediction = prediction.reshape(batch_size * seq_len, -1)  #prediction: [batch size * seq len, vocab size]\n",
        "        target = target.reshape(-1)\n",
        "        loss = criterion(prediction, target)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * seq_len\n",
        "    return epoch_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1NDYsk-9AaTO"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    num_batches = data.shape[-1]\n",
        "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
        "    num_batches = data.shape[-1]\n",
        "\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, num_batches - 1, seq_len):\n",
        "            hidden = model.detach_hidden(hidden)\n",
        "            src, target = get_batch(data, seq_len, idx)\n",
        "            src, target = src.to(device), target.to(device)\n",
        "            batch_size= src.shape[0]\n",
        "\n",
        "            prediction, hidden = model(src, hidden)\n",
        "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
        "            target = target.reshape(-1)\n",
        "\n",
        "            loss = criterion(prediction, target)\n",
        "            epoch_loss += loss.item() * seq_len\n",
        "    return epoch_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh6rNfYGAaTO"
      },
      "source": [
        "Here we will be using a `ReduceLROnPlateau` learning scheduler which decreases the learning rate by a factor, if the loss don't improve by a certain epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v1L-ozDAaTO",
        "outputId": "d953ecfe-f946-461a-b6ba-d010a162ec22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Perplexity: 368.487\n",
            "\tValid Perplexity: 186.903\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 1\n",
        "seq_len  = 50 #<----decoding length\n",
        "clip    = 0.25\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = train(model, train_data, optimizer, criterion,\n",
        "                batch_size, seq_len, clip, device)\n",
        "    valid_loss = evaluate(model, valid_data, criterion, batch_size,\n",
        "                seq_len, device)\n",
        "\n",
        "    lr_scheduler.step(valid_loss)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-val-lstm_lm.pt')\n",
        "\n",
        "    print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyOkhw53AaTO"
      },
      "source": [
        "## 6. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCs8RCJ0AaTO",
        "outputId": "87329860-9844-4c27-f04a-d1f04179734e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Perplexity: 183.943\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
        "test_loss = evaluate(model, test_data, criterion, batch_size, seq_len, device)\n",
        "print(f'Test Perplexity: {math.exp(test_loss):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l116vTHyAaTO"
      },
      "source": [
        "## 7. Real-world inference\n",
        "\n",
        "Here we take the prompt, tokenize, encode and feed it into the model to get the predictions.  We then apply softmax while specifying that we want the output due to the last word in the sequence which represents the prediction for the next word.  We divide the logits by a temperature value to alter the model’s confidence by adjusting the softmax probability distribution.\n",
        "\n",
        "Once we have the Softmax distribution, we randomly sample it to make our prediction on the next word. If we get <unk> then we give that another try.  Once we get <eos> we stop predicting.\n",
        "    \n",
        "We decode the prediction back to strings last lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "f2kYaMUmAaTO"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, device, seed=None):\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    model.eval()\n",
        "    tokens = tokenizer(prompt)\n",
        "    indices = [vocab[t] for t in tokens]\n",
        "    batch_size = 1\n",
        "    hidden = model.init_hidden(batch_size, device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(max_seq_len):\n",
        "            src = torch.LongTensor([indices]).to(device)\n",
        "            prediction, hidden = model(src, hidden)\n",
        "\n",
        "            #prediction: [batch size, seq len, vocab size]\n",
        "            #prediction[:, -1]: [batch size, vocab size] #probability of last vocab\n",
        "\n",
        "            probs = torch.softmax(prediction[:, -1] / temperature, dim=-1)\n",
        "            prediction = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "            while prediction == vocab['<unk>']: #if it is unk, we sample again\n",
        "                prediction = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "            if prediction == vocab['<eos>']:    #if it is eos, we stop\n",
        "                break\n",
        "\n",
        "            indices.append(prediction) #autoregressive, thus output becomes input\n",
        "\n",
        "    itos = vocab.get_itos()\n",
        "    tokens = [itos[i] for i in indices]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnhPpVpcAaTP",
        "outputId": "9faddb0b-d3e4-44ce-9687-b3700ae27116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "lionel is a lot of the film , but i am a very\n",
            "\n",
            "0.7\n",
            "lionel is a surprise that they jumped on the movie ( other )\n",
            "\n",
            "0.75\n",
            "lionel is a surprise that they jumped on the movie ( other )\n",
            "\n",
            "0.8\n",
            "lionel is a surprise that they jumped on the movie ( other )\n",
            "\n",
            "1.0\n",
            "lionel is a surprise that they jumped on the movie ( other peoples\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = 'Lionel is a'\n",
        "max_seq_len = 10\n",
        "seed = 0\n",
        "\n",
        "#smaller the temperature, more diverse tokens but comes\n",
        "#with a tradeoff of less-make-sense sentence\n",
        "temperatures = [0.5, 0.7, 0.75, 0.8, 1.0]\n",
        "for temperature in temperatures:\n",
        "    generation = generate(prompt, max_seq_len, temperature, model, tokenizer,\n",
        "                          vocab, device, seed)\n",
        "    print(str(temperature)+'\\n'+' '.join(generation)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WeZI1r7nqtpW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Assuming 'model' is your PyTorch model\n",
        "torch.save(model.state_dict(), 'your_model_path.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4rF5O9lg3LZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9b83ea421064bc694c72d3313afcc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4b46668887d4a41bbd091536dd1c458",
              "IPY_MODEL_c40e3009eddd46a7a0cf3d875843f979",
              "IPY_MODEL_cd1db1de2f764317be63eaa62342d3ec"
            ],
            "layout": "IPY_MODEL_8ef21616aee947c9899a2e5e16f36c89"
          }
        },
        "e4b46668887d4a41bbd091536dd1c458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ada2fe3a239454687876f99a6d26e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_af3a031889694fc7a8aa18473453a771",
            "value": "Map: 100%"
          }
        },
        "c40e3009eddd46a7a0cf3d875843f979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_594871d79ce94743bbc47dd402a9257b",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b721e3d72913466c8c05e4b4813875b3",
            "value": 25000
          }
        },
        "cd1db1de2f764317be63eaa62342d3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64e92b3b1e5d4e9082928e25453f86c7",
            "placeholder": "​",
            "style": "IPY_MODEL_64f7e2a926a94d6390f7d793a338e26b",
            "value": " 25000/25000 [00:06&lt;00:00, 4327.04 examples/s]"
          }
        },
        "8ef21616aee947c9899a2e5e16f36c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ada2fe3a239454687876f99a6d26e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3a031889694fc7a8aa18473453a771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "594871d79ce94743bbc47dd402a9257b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b721e3d72913466c8c05e4b4813875b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64e92b3b1e5d4e9082928e25453f86c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f7e2a926a94d6390f7d793a338e26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3299572c8ed4f6e9fab21828ed7e66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dea9b9245f374ff28e0b68ad6b297827",
              "IPY_MODEL_5e4f98ea859c4ed9bd8dc5824406d5ea",
              "IPY_MODEL_a672667720f643a39a1ed0027f16d7b1"
            ],
            "layout": "IPY_MODEL_0a4a1b4ad11949ba99516394997ecedb"
          }
        },
        "dea9b9245f374ff28e0b68ad6b297827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af05515866de4362864128815f9711a9",
            "placeholder": "​",
            "style": "IPY_MODEL_e17a9d9f2b9d4ea5b06de66d83d89908",
            "value": "Map: 100%"
          }
        },
        "5e4f98ea859c4ed9bd8dc5824406d5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8252c272a494dffa3373534ac79fad2",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0e1b80ba96946ba8ff81ea8e248451e",
            "value": 25000
          }
        },
        "a672667720f643a39a1ed0027f16d7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59f6ca892b84f0c967aeac3934090e6",
            "placeholder": "​",
            "style": "IPY_MODEL_2e60932808c74a1283146f5258a190eb",
            "value": " 25000/25000 [00:05&lt;00:00, 4338.34 examples/s]"
          }
        },
        "0a4a1b4ad11949ba99516394997ecedb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af05515866de4362864128815f9711a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17a9d9f2b9d4ea5b06de66d83d89908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8252c272a494dffa3373534ac79fad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e1b80ba96946ba8ff81ea8e248451e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a59f6ca892b84f0c967aeac3934090e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e60932808c74a1283146f5258a190eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d1aafcdd84400682678f5f363a9abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25749ec8120e454dbd48a6311dae17ec",
              "IPY_MODEL_4623a2ad99b94457b84c01bb2dbe9dfe",
              "IPY_MODEL_bfd32cfabf3140ec9fe0f5586cdbe322"
            ],
            "layout": "IPY_MODEL_a198e66eae244356b6e3e0a879a77b59"
          }
        },
        "25749ec8120e454dbd48a6311dae17ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5463205ff5e4a33b5d61167c23a40e9",
            "placeholder": "​",
            "style": "IPY_MODEL_3ee5d49aa9d34bd497a75773979e36fa",
            "value": "Map: 100%"
          }
        },
        "4623a2ad99b94457b84c01bb2dbe9dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_322880b88e304e869c624eb100c1a7e4",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c55e553f6e704797bc7121b5d0892c8b",
            "value": 50000
          }
        },
        "bfd32cfabf3140ec9fe0f5586cdbe322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a07c4425c1a4454b30bf8090600b313",
            "placeholder": "​",
            "style": "IPY_MODEL_e07801ab067e4f64a02b8571ffcbd5dd",
            "value": " 50000/50000 [00:12&lt;00:00, 4477.64 examples/s]"
          }
        },
        "a198e66eae244356b6e3e0a879a77b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5463205ff5e4a33b5d61167c23a40e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee5d49aa9d34bd497a75773979e36fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "322880b88e304e869c624eb100c1a7e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55e553f6e704797bc7121b5d0892c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a07c4425c1a4454b30bf8090600b313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07801ab067e4f64a02b8571ffcbd5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}